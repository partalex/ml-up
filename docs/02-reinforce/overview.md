## ğŸ“‹ Å TA JE REINFORCE?

**REINFORCE** je **policy gradient** algoritam koji **direktno uÄi stohastiÄku politiku** Ï€_Î¸(a|s).

### Glavna ideja:

1. **Sakupi celu epizodu**: (sâ‚€, aâ‚€, râ‚€), (sâ‚, aâ‚, râ‚), ..., (sâ‚œ, aâ‚œ, râ‚œ)
2. **IzraÄunaj returns**: Gâ‚œ = râ‚œ + Î³Â·râ‚œâ‚Šâ‚ + Î³Â²Â·râ‚œâ‚Šâ‚‚ + ...
3. **AÅ¾uriraj politiku**: Î¸ â† Î¸ + Î±Â·Gâ‚œÂ·âˆ‡log Ï€(a|s)

### Softmax politika:

```
Ï€(a|s) = exp(Î¸(s,a)) / Î£ exp(Î¸(s,a'))
```

---

## âœ… IMPLEMENTIRANE FUNKCIONALNOSTI

### Algoritam

- âœ… Softmax politika (numeriÄki stabilna)
- âœ… Monte Carlo returns
- âœ… Policy gradient update
- âœ… Promenljiva stopa uÄenja: Î± = ln(e+1)/(e+1)
- âœ… Konstantna stopa uÄenja: Î± = 0.01

### PraÄ‡enje napretka (kako je traÅ¾eno)

- âœ… **Zamrzavanje politike** svakih 100 epizoda
- âœ… **10 test epizoda** za evaluaciju
- âœ… **ProseÄna ukupna nagrada** se raÄuna i beleÅ¾i

### Grafici

- âœ… **Graf 1**: Nagrade tokom treniranja
- âœ… **Graf 2**: ProseÄna nagrada u 10 test epizoda ğŸ“Š
- âœ… **Graf 3**: Parametri politike Î¸(s,a) ğŸ“Š
- âœ… **Graf 4**: NauÄena politika (grid)

### Parametri

- âœ… **Î³ = 0.9** (kako je traÅ¾eno)
- âœ… **2000 epizoda** treniranja
- âœ… **Test svakih 100 epizoda**

---

## ğŸ“Š KLJUÄŒNI GRAFICI

### Graf 2: ProseÄna nagrada u 10 test epizoda

**Ovo pokazuje kako se nagrada menja tokom uÄenja!**

- X-osa: Epizoda (100, 200, ..., 2000)
- Y-osa: ProseÄna nagrada
- Trebalo bi da raste: 0.0 â†’ 1.0 â†’ 2.0+

### Graf 3: Parametri politike

**Ovo pokazuje kako se Î¸(s,a) menjaju!**

- Prikazuje proseÄne Î¸ vrednosti za ne-terminalna stanja
- Konvergiraju ka stabilnim vrednostima
- RazliÄite linije za razliÄita stanja (A1, A2, A3, ...)

---

## ğŸ¯ RAZLIKE OD Q-LEARNING

|               | Q-Learning      | REINFORCE    |
|---------------|-----------------|--------------|
| **Tip**       | Value-based     | Policy-based |
| **UÄi**       | Q(s,a)          | Ï€_Î¸(a,s)     |
| **Politika**  | DeterministiÄka | StohastiÄka  |
| **Update**    | TD (po koraku)  | MC (epizoda) |
| **Brzina**    | BrÅ¾a            | Sporija      |
| **Varijansa** | Manja           | VeÄ‡a         |

---

## ğŸš€ EKSPERIMENTI

### Eksperiment 1: Promenljiva Î±

- Stopa uÄenja: Î± = ln(e+1)/(e+1)
- PoÄinje ~0.69, pada na ~0.14
- Stabilnija konvergencija

### Eksperiment 2: Konstantna Î± = 0.01

- Fiksna stopa uÄenja
- Za poreÄ‘enje brzine konvergencije

### Output

Za svaki eksperiment:

- PNG grafik sa 4 panela
- Konzolni ispis napretka
- Finalna proseÄna nagrada

---

## ğŸ’¡ OÄŒEKIVANI REZULTATI

### ProseÄna nagrada u toku uÄenja:

```
Epizoda    OÄekivana nagrada
  100      0.0 - 0.5  (sluÄajne akcije)
  500      0.5 - 1.0  (rano uÄenje)
 1000      1.0 - 1.5  (sredina)
 1500      1.5 - 2.0  (kasno uÄenje)
 2000      2.0 - 2.5  (dobra politika)
```

### NauÄena politika:

- âœ… Agent ide ka **B5** (nagrada +3)
- âœ… Izbegava **B1 i B3** (nagrada -1)
- âœ… StohastiÄka (daje verovatnoÄ‡e, ne fiksne akcije)
- âœ… Uzima u obzir stohastiÄnost okruÅ¾enja (0.7)

---

## ğŸ“ TEORIJA (kratko)

### REINFORCE update:

```python
for t in range(T):
    Gâ‚œ = Î£
    Î³áµÂ·râ‚œâ‚Šâ‚–  # Monte Carlo return
    for akciju a:
        Î¸(sâ‚œ, a) += Î±Â·Gâ‚œÂ·âˆ‡log
        Ï€(a | sâ‚œ)
```

### Softmax gradijent:

```python
if a == akcija_uzeta:
    âˆ‡log
    Ï€ = 1 - Ï€(a | s)
else:
    âˆ‡log
    Ï€ = -Ï€(a | s)
```

Ovo je **score function gradient estimator** - ne treba znati dinamiku okruÅ¾enja!

---

## âœ… COMPLIANCE SA ZADATKOM

Zadatak je traÅ¾io:

| Zahtev                             | Implementirano              |
|------------------------------------|-----------------------------|
| REINFORCE algoritam                | âœ…                           |
| Zamrzavati nauÄenu politiku        | âœ… `run_test_episodes()`     |
| 10 epizoda interakcije             | âœ… `num_episodes=10`         |
| ProseÄna ukupna nagrada            | âœ… RaÄuna se i beleÅ¾i        |
| **GrafiÄki:** Nagrada u 10 epizoda | âœ… Graf 2                    |
| **GrafiÄki:** Parametri Î¸(s,a)     | âœ… Graf 3                    |
| Eksperimentisati sa Î±              | âœ… Promenljiva vs konstantna |
| Î³ = 0.9                            | âœ…                           |

---

## ğŸ› TROUBLESHOOTING

**Q: "No module named 'numpy'"**  
A: `pip install numpy matplotlib`

**Q: Sporo izvrÅ¡avanje**  
A: Normalno! 2000 epizoda Ã— 2 eksperimenta = 2-3 min. REINFORCE je sporiji jer koristi Monte Carlo.

**Q: Nagrade osciliraju**  
A: Normalno! REINFORCE ima veÄ‡u varijansu. Zato pratimo prosek u 10 epizoda.

**Q: Politika nije deterministiÄka**  
A: To je FEATURE! REINFORCE uÄi stohastiÄku politiku. VerovatnoÄ‡e pokazuju "sigurnost".

**Q: Agent ne postiÅ¾e +3 uvek**  
A: Normalno! OkruÅ¾enje je stohastiÄno (0.7), teÅ¡ko je uvek iÄ‡i ka B5.

---

## ğŸ¯ ZAKLJUÄŒAK

### âœ… STATUS: KOMPLETNO IMPLEMENTIRANO

Svi zahtevi iz zadatka su ispunjeni:

- âœ… REINFORCE algoritam
- âœ… PraÄ‡enje napretka (zamrzavanje, 10 epizoda)
- âœ… GrafiÄki prikaz nagrada
- âœ… GrafiÄki prikaz parametara Î¸
- âœ… Eksperimenti sa Î±
- âœ… Î³ = 0.9

### Dodatno:

- âœ… Mypy tipizacija (no errors)
- âœ… 4 grafikona po eksperimentu
- âœ… Grid vizualizacija politike
- âœ… Testovi
- âœ… Kompletna dokumentacija

---

## ğŸš€ BRZI START (joÅ¡ jednom)

```bash
pip install numpy matplotlib
python src/02-reinforce-reinforce-main.py
```

**Trajanje**: 2-3 minuta  
**Output**: 2 PNG grafika + analiza
